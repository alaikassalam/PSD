{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "12dc330c",
   "metadata": {},
   "source": [
    "# Deteksi Outlier ABOD "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ba812e5",
   "metadata": {},
   "source": [
    "## Angle-Based Outlier Detection (ABOD)  \n",
    "Angle-Based Outlier Detection (ABOD) adalah pendekatan geometris untuk mengidentifikasi outlier dalam data berdimensi tinggi dengan menganalisis varians sudut yang dibentuk oleh vektor-vektor dari suatu titik ke tetangganya.\n",
    "\n",
    "Dalam satu himpunan data, titik-titik normal cenderung memiliki sudut-sudut yang serupa antara pasangan vektor yang menghubungkannya ke titik lain. Sebaliknya, outlier sering kali terletak di tepi dan membentuk rentang sudut yang sangat luas terhadap tetangganya â€” artinya, varians sudut mereka tinggi."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cb8c073",
   "metadata": {},
   "source": [
    "## Algoritma Angle-Based Outlier Detection (ABOD)\n",
    "\n",
    "1. Untuk setiap titik \\( p_i \\) dalam dataset:\n",
    "   - Hitung semua vektor pasangan dari \\( p_i \\) ke titik lainnya:  \n",
    "     $$\n",
    "     \\vec{v}_{ij} = p_j - p_i\n",
    "     $$\n",
    "   - Untuk setiap pasangan vektor seperti $((\\vec{v}_{ij}, \\vec{v}_{ik})$ , hitung sudut di antara keduanya menggunakan rumus hasil kali titik:  \n",
    "     $$\n",
    "     \\cos(\\theta_{ijk}) = \\frac{\\vec{v}_{ij} \\cdot \\vec{v}_{ik}}{\\|\\vec{v}_{ij}\\| \\cdot \\|\\vec{v}_{ik}\\|}\n",
    "     $$\n",
    "   - Hitung **varians** dari semua sudut tersebut untuk titik \\( p_i \\).\n",
    "\n",
    "\n",
    "2. Skor outlier untuk titik $ p_i $ adalah varians sudut:  \n",
    "   $$\n",
    "   ABOD(p_i) = \\mathrm{Var}(\\theta_{ijk}) \\quad \\text{untuk semua } j, k \\neq i\n",
    "   $$\n",
    "\n",
    "\n",
    "3. Titik-titik dengan **varians sudut tinggi** ditandai sebagai **outlier**.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "390f0a50",
   "metadata": {},
   "source": [
    "## Implementasi\n",
    "### Import library yang dibutuhkan "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6151905d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from dotenv import load_dotenv\n",
    "from sqlalchemy import create_engine"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afc452bd",
   "metadata": {},
   "source": [
    "### Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "01f3d39d",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "\n",
    "# Ambil variabel dari .env\n",
    "user_postgres = os.getenv(\"USER_POSTGRES\")\n",
    "password_postgres = os.getenv(\"PASS_POSTGRES\")\n",
    "host_postgres = os.getenv(\"HOST_POSTGRES\")\n",
    "port_postgres = os.getenv(\"PORT_POSTGRES\")\n",
    "db_postgres = os.getenv(\"DB_POSTGRES\")\n",
    "\n",
    "user_mysql = os.getenv(\"USER_MYSQL\")\n",
    "password_mysql = os.getenv(\"PASS_MYSQL\")\n",
    "host_mysql = os.getenv(\"HOST_MYSQL\")\n",
    "port_mysql = os.getenv(\"PORT_MYSQL\")\n",
    "db_mysql = os.getenv(\"DB_MYSQL\")\n",
    "\n",
    "\n",
    "postgres_conn = f\"postgresql+psycopg2://{user_postgres}:{password_postgres}@{host_postgres}:{port_postgres}/{db_postgres}\"\n",
    "\n",
    "mysql_conn = f\"mysql+pymysql://{user_mysql}:{password_mysql}@{host_mysql}:{port_mysql}/{db_mysql}\"\n",
    "\n",
    "postgres_engine = create_engine(postgres_conn)\n",
    "postgres_engine = create_engine(mysql_conn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "363d9ba3",
   "metadata": {},
   "source": [
    "### Membuat koneksi (engine) dan mengambil dari database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dca4ddb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Engine untuk PostgreSQL\n",
    "postgres_engine = create_engine(postgres_conn)\n",
    "\n",
    "# Engine untuk MySQL\n",
    "mysql_engine = create_engine(mysql_conn)\n",
    "\n",
    "\n",
    "# Ambil data dari MySQL\n",
    "mysql_df_iris = pd.read_sql(\"SELECT * FROM iris_full\", mysql_engine)\n",
    "\n",
    "# Ambil data dari PostgreSQL\n",
    "postgres_df_iris = pd.read_sql(\"SELECT * FROM iris_full\", postgres_engine)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41ea8cc3",
   "metadata": {},
   "source": [
    "### Mengabungkan 2 database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "22639911",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      id  petal length_x  petal width_x Class_x sepal length_x sepal width_x  \\\n",
      "0      1             NaN            NaN     NaN            NaN           NaN   \n",
      "1      1             NaN            NaN     NaN            NaN           NaN   \n",
      "2      2             NaN            NaN     NaN            NaN           NaN   \n",
      "3      2             NaN            NaN     NaN            NaN           NaN   \n",
      "4      3             NaN            NaN     NaN            NaN           NaN   \n",
      "..   ...             ...            ...     ...            ...           ...   \n",
      "295  148             5.2            2.0    None           None          None   \n",
      "296  149             5.4            2.3    None           None          None   \n",
      "297  149             5.4            2.3    None           None          None   \n",
      "298  150             5.1            1.8    None           None          None   \n",
      "299  150             5.1            1.8    None           None          None   \n",
      "\n",
      "     sepal length_y  sepal width_y         Class_y  petal length_y  \\\n",
      "0               5.1            3.5            None             NaN   \n",
      "1               5.1            3.5     Iris-setosa             1.4   \n",
      "2               4.9            3.0            None             NaN   \n",
      "3               4.9            3.0     Iris-setosa             1.4   \n",
      "4               4.7            3.2            None             NaN   \n",
      "..              ...            ...             ...             ...   \n",
      "295             6.5            3.0  Iris-virginica             5.2   \n",
      "296             6.2            3.4            None             NaN   \n",
      "297             6.2            3.4  Iris-virginica             5.4   \n",
      "298             5.9            3.0            None             NaN   \n",
      "299             5.9            3.0  Iris-virginica             5.1   \n",
      "\n",
      "     petal width_y  \n",
      "0              NaN  \n",
      "1              0.2  \n",
      "2              NaN  \n",
      "3              0.2  \n",
      "4              NaN  \n",
      "..             ...  \n",
      "295            2.0  \n",
      "296            NaN  \n",
      "297            2.3  \n",
      "298            NaN  \n",
      "299            1.8  \n",
      "\n",
      "[300 rows x 11 columns]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "merge_df = pd.merge(mysql_df_iris, postgres_df_iris, left_on=\"id\", right_on='id', how='outer')\n",
    "print(merge_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe508b64",
   "metadata": {},
   "source": [
    "### Salinan data\n",
    "Buat salinan data dari hasil penggabungan "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "78337c8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train = merge_df.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f07dec4e",
   "metadata": {},
   "source": [
    "### Model ABOD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "88ecc84b",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pycaret'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpycaret\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01manomaly\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# === 1. Pastikan dataset sudah ada ===\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mJumlah baris:\u001b[39m\u001b[38;5;124m\"\u001b[39m, data_train\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m])\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'pycaret'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from pycaret.anomaly import *\n",
    "\n",
    "# === 1. Pastikan dataset sudah ada ===\n",
    "print(\"Jumlah baris:\", data_train.shape[0])\n",
    "print(\"Jumlah kolom:\", data_train.shape[1])\n",
    "print(\"Kolom dataset:\", list(data_train.columns))\n",
    "print(data_train.head())\n",
    "\n",
    "# === 2. Pilih hanya kolom numerik (biar PyCaret tidak error) ===\n",
    "fitur = data_train.select_dtypes(include=['int64', 'float64'])\n",
    "print(\"\\nKolom numerik yang dipakai untuk anomaly detection:\", list(fitur.columns))\n",
    "\n",
    "# === 3. Setup PyCaret Anomaly Detection (versi terbaru) ===\n",
    "from pycaret.anomaly import setup, create_model, assign_model\n",
    "exp_ano = setup(\n",
    "    data=fitur,\n",
    "    session_id=42\n",
    ")\n",
    "\n",
    "# === 4. Buat model ABOD ===\n",
    "abod_model = create_model('abod')\n",
    "\n",
    "# === 5. Assign label anomaly ===\n",
    "dataset_outliers = assign_model(abod_model)\n",
    "\n",
    "# === 6. Hapus baris outlier (Anomaly == 1 artinya normal, -1 artinya outlier) ===\n",
    "dataset_clean = dataset_outliers[dataset_outliers['Anomaly'] == 1]\n",
    "\n",
    "print(\"\\nJumlah data awal:\", len(dataset_outliers))\n",
    "print(\"Jumlah data setelah outlier dihapus:\", len(dataset_clean))\n",
    "dataset_clean.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ed4dcfb",
   "metadata": {},
   "source": [
    "### Menghapus data dengan skor outlier tertinggi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5259b697",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data setelah 2 outlier tertinggi dihapus:\n",
      "   id  petal length_x  petal width_x  sepal length_y  sepal width_y  \\\n",
      "0  36             1.2            0.2             5.0            3.2   \n",
      "1  36             1.2            0.2             5.0            3.2   \n",
      "2  37             1.3            0.2             5.5            3.5   \n",
      "3  37             1.3            0.2             5.5            3.5   \n",
      "4  38             1.5            0.1             4.9            3.1   \n",
      "\n",
      "   petal length_y  petal width_y  Anomaly  Anomaly_Score  \n",
      "0             NaN            NaN        0      -0.011465  \n",
      "1             1.2            0.2        0      -0.010103  \n",
      "2             NaN            NaN        0      -0.025892  \n",
      "3             1.3            0.2        0      -0.024060  \n",
      "4             NaN            NaN        0      -0.082164  \n"
     ]
    }
   ],
   "source": [
    "# Urutkan dataset_outliers berdasarkan skor outlier (descending)\n",
    "outliers_sorted = dataset_outliers.sort_values(by=\"Anomaly_Score\", ascending=False)\n",
    "\n",
    "# Ambil index 2 skor outlier tertinggi\n",
    "top2_outliers_index = outliers_sorted.head(2).index\n",
    "\n",
    "# Hapus 2 data tersebut dari dataset_outliers\n",
    "dataset_clean_top2 = dataset_outliers.drop(index=top2_outliers_index)\n",
    "\n",
    "print(\"Data setelah 2 outlier tertinggi dihapus:\")\n",
    "print(dataset_clean_top2.head())\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}