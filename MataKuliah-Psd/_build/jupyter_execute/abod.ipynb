{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "12dc330c",
   "metadata": {},
   "source": [
    "# Deteksi Outlier ABOD "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ba812e5",
   "metadata": {},
   "source": [
    "## Angle-Based Outlier Detection (ABOD)  \n",
    "Angle-Based Outlier Detection (ABOD) adalah pendekatan geometris untuk mengidentifikasi outlier dalam data berdimensi tinggi dengan menganalisis varians sudut yang dibentuk oleh vektor-vektor dari suatu titik ke tetangganya.\n",
    "\n",
    "Dalam satu himpunan data, titik-titik normal cenderung memiliki sudut-sudut yang serupa antara pasangan vektor yang menghubungkannya ke titik lain. Sebaliknya, outlier sering kali terletak di tepi dan membentuk rentang sudut yang sangat luas terhadap tetangganya â€” artinya, varians sudut mereka tinggi."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cb8c073",
   "metadata": {},
   "source": [
    "## Algoritma Angle-Based Outlier Detection (ABOD)\n",
    "\n",
    "1. Untuk setiap titik \\( p_i \\) dalam dataset:\n",
    "   - Hitung semua vektor pasangan dari \\( p_i \\) ke titik lainnya:  \n",
    "     $$\n",
    "     \\vec{v}_{ij} = p_j - p_i\n",
    "     $$\n",
    "   - Untuk setiap pasangan vektor seperti $((\\vec{v}_{ij}, \\vec{v}_{ik})$ , hitung sudut di antara keduanya menggunakan rumus hasil kali titik:  \n",
    "     $$\n",
    "     \\cos(\\theta_{ijk}) = \\frac{\\vec{v}_{ij} \\cdot \\vec{v}_{ik}}{\\|\\vec{v}_{ij}\\| \\cdot \\|\\vec{v}_{ik}\\|}\n",
    "     $$\n",
    "   - Hitung **varians** dari semua sudut tersebut untuk titik \\( p_i \\).\n",
    "\n",
    "\n",
    "2. Skor outlier untuk titik $ p_i $ adalah varians sudut:  \n",
    "   $$\n",
    "   ABOD(p_i) = \\mathrm{Var}(\\theta_{ijk}) \\quad \\text{untuk semua } j, k \\neq i\n",
    "   $$\n",
    "\n",
    "\n",
    "3. Titik-titik dengan **varians sudut tinggi** ditandai sebagai **outlier**.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "390f0a50",
   "metadata": {},
   "source": [
    "## Implementasi\n",
    "### Import library yang dibutuhkan "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6151905d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from dotenv import load_dotenv\n",
    "from sqlalchemy import create_engine"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afc452bd",
   "metadata": {},
   "source": [
    "### Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "01f3d39d",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "\n",
    "# Ambil variabel dari .env\n",
    "user_postgres = os.getenv(\"USER_POSTGRES\")\n",
    "password_postgres = os.getenv(\"PASS_POSTGRES\")\n",
    "host_postgres = os.getenv(\"HOST_POSTGRES\")\n",
    "port_postgres = os.getenv(\"PORT_POSTGRES\")\n",
    "db_postgres = os.getenv(\"DB_POSTGRES\")\n",
    "\n",
    "user_mysql = os.getenv(\"USER_MYSQL\")\n",
    "password_mysql = os.getenv(\"PASS_MYSQL\")\n",
    "host_mysql = os.getenv(\"HOST_MYSQL\")\n",
    "port_mysql = os.getenv(\"PORT_MYSQL\")\n",
    "db_mysql = os.getenv(\"DB_MYSQL\")\n",
    "\n",
    "\n",
    "postgres_conn = f\"postgresql+psycopg2://{user_postgres}:{password_postgres}@{host_postgres}:{port_postgres}/{db_postgres}\"\n",
    "\n",
    "mysql_conn = f\"mysql+pymysql://{user_mysql}:{password_mysql}@{host_mysql}:{port_mysql}/{db_mysql}\"\n",
    "\n",
    "postgres_engine = create_engine(postgres_conn)\n",
    "postgres_engine = create_engine(mysql_conn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "363d9ba3",
   "metadata": {},
   "source": [
    "### Membuat koneksi (engine) dan mengambil dari database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dca4ddb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Engine untuk PostgreSQL\n",
    "postgres_engine = create_engine(postgres_conn)\n",
    "\n",
    "# Engine untuk MySQL\n",
    "mysql_engine = create_engine(mysql_conn)\n",
    "\n",
    "\n",
    "# Ambil data dari MySQL\n",
    "mysql_df_iris = pd.read_sql(\"SELECT * FROM iris_full\", mysql_engine)\n",
    "\n",
    "# Ambil data dari PostgreSQL\n",
    "postgres_df_iris = pd.read_sql(\"SELECT * FROM iris_full\", postgres_engine)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41ea8cc3",
   "metadata": {},
   "source": [
    "### Mengabungkan 2 database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "22639911",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     id  petal length_x  petal width_x Class_x sepal length_x sepal width_x  \\\n",
      "0    36             1.2            0.2    None           None          None   \n",
      "1    36             1.2            0.2    None           None          None   \n",
      "2    37             1.3            0.2    None           None          None   \n",
      "3    37             1.3            0.2    None           None          None   \n",
      "4    38             1.5            0.1    None           None          None   \n",
      "..   ..             ...            ...     ...            ...           ...   \n",
      "295  33             NaN            NaN     NaN            NaN           NaN   \n",
      "296  34             NaN            NaN     NaN            NaN           NaN   \n",
      "297  34             NaN            NaN     NaN            NaN           NaN   \n",
      "298  35             NaN            NaN     NaN            NaN           NaN   \n",
      "299  35             NaN            NaN     NaN            NaN           NaN   \n",
      "\n",
      "     sepal length_y  sepal width_y      Class_y  petal length_y  petal width_y  \n",
      "0               5.0            3.2         None             NaN            NaN  \n",
      "1               5.0            3.2  Iris-setosa             1.2            0.2  \n",
      "2               5.5            3.5         None             NaN            NaN  \n",
      "3               5.5            3.5  Iris-setosa             1.3            0.2  \n",
      "4               4.9            3.1         None             NaN            NaN  \n",
      "..              ...            ...          ...             ...            ...  \n",
      "295             5.2            4.1  Iris-setosa             1.5            0.1  \n",
      "296             5.5            4.2         None             NaN            NaN  \n",
      "297             5.5            4.2  Iris-setosa             1.4            0.2  \n",
      "298             4.9            3.1         None             NaN            NaN  \n",
      "299             4.9            3.1  Iris-setosa             1.5            0.1  \n",
      "\n",
      "[300 rows x 11 columns]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "merge_df = pd.merge(mysql_df_iris, postgres_df_iris, left_on=\"id\", right_on='id', how='outer')\n",
    "print(merge_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe508b64",
   "metadata": {},
   "source": [
    "### Salinan data\n",
    "Buat salinan data dari hasil penggabungan "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "78337c8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train = merge_df.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f07dec4e",
   "metadata": {},
   "source": [
    "### Model ABOD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "88ecc84b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pycaret.anomaly import *\n",
    "\n",
    "# === 1. Pastikan dataset sudah ada ===\n",
    "print(\"Jumlah baris:\", data_train.shape[0])\n",
    "print(\"Jumlah kolom:\", data_train.shape[1])\n",
    "print(\"Kolom dataset:\", list(data_train.columns))\n",
    "print(data_train.head())\n",
    "\n",
    "# === 2. Pilih hanya kolom numerik (biar PyCaret tidak error) ===\n",
    "fitur = data_train.select_dtypes(include=['int64', 'float64'])\n",
    "print(\"\\nKolom numerik yang dipakai untuk anomaly detection:\", list(fitur.columns))\n",
    "\n",
    "# === 3. Setup PyCaret Anomaly Detection (versi terbaru) ===\n",
    "from pycaret.anomaly import setup, create_model, assign_model\n",
    "exp_ano = setup(\n",
    "    data=fitur,\n",
    "    session_id=42\n",
    ")\n",
    "\n",
    "# === 4. Buat model ABOD ===\n",
    "abod_model = create_model('abod')\n",
    "\n",
    "# === 5. Assign label anomaly ===\n",
    "dataset_outliers = assign_model(abod_model)\n",
    "\n",
    "# === 6. Hapus baris outlier (Anomaly == 1 artinya normal, -1 artinya outlier) ===\n",
    "dataset_clean = dataset_outliers[dataset_outliers['Anomaly'] == 1]\n",
    "\n",
    "print(\"\\nJumlah data awal:\", len(dataset_outliers))\n",
    "print(\"Jumlah data setelah outlier dihapus:\", len(dataset_clean))\n",
    "dataset_clean.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ed4dcfb",
   "metadata": {},
   "source": [
    "### Menghapus data dengan skor outlier tertinggi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5259b697",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data setelah 2 outlier tertinggi dihapus:\n",
      "   id  petal length_x  petal width_x  sepal length_y  sepal width_y  \\\n",
      "0  36             1.2            0.2             5.0            3.2   \n",
      "1  36             1.2            0.2             5.0            3.2   \n",
      "2  37             1.3            0.2             5.5            3.5   \n",
      "3  37             1.3            0.2             5.5            3.5   \n",
      "4  38             1.5            0.1             4.9            3.1   \n",
      "\n",
      "   petal length_y  petal width_y  Anomaly  Anomaly_Score  \n",
      "0             NaN            NaN        0      -0.011465  \n",
      "1             1.2            0.2        0      -0.010103  \n",
      "2             NaN            NaN        0      -0.025892  \n",
      "3             1.3            0.2        0      -0.024060  \n",
      "4             NaN            NaN        0      -0.082164  \n"
     ]
    }
   ],
   "source": [
    "# Urutkan dataset_outliers berdasarkan skor outlier (descending)\n",
    "outliers_sorted = dataset_outliers.sort_values(by=\"Anomaly_Score\", ascending=False)\n",
    "\n",
    "# Ambil index 2 skor outlier tertinggi\n",
    "top2_outliers_index = outliers_sorted.head(2).index\n",
    "\n",
    "# Hapus 2 data tersebut dari dataset_outliers\n",
    "dataset_clean_top2 = dataset_outliers.drop(index=top2_outliers_index)\n",
    "\n",
    "print(\"Data setelah 2 outlier tertinggi dihapus:\")\n",
    "print(dataset_clean_top2.head())\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}